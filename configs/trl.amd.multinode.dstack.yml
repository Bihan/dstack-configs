type: task
name: trl-amd-multinode-dstack

nodes: 2

# Mount the system libraries folder from the host
volumes:
  - /usr/local/lib:/mnt/lib

image: rocm/dev-ubuntu-22.04:6.4-complete
env:
  - NCCL_DEBUG=INFO
  - WANDB_API_KEY
  - HF_TOKEN
  - HUB_MODEL_ID
  - MODEL_ID=Qwen/Qwen3-8B
commands:
  # Setup
  - apt-get update && apt-get install -y git cmake libibverbs1 #Contains libibverbs.so.1, required by libbnxt_re-rdmav34.so
  - pip install torch --index-url https://download.pytorch.org/whl/nightly/rocm6.4 # default torch from transformers does not detect ROCm GPUs.
  - pip install transformers peft wandb
  # Install bitsandbytes
  # - git clone https://github.com/ROCm/bitsandbytes
  # - cd bitsandbytes
  # - git checkout rocm_enabled_multi_backend
  # - pip install -r requirements-dev.txt
  # - cmake -DBNB_ROCM_ARCH="gfx942" -DCOMPUTE_BACKEND=hip -S .
  # - python3 setup.py install
  # - cd ..
  # Install Flash attention
  # - git clone --recursive https://github.com/ROCm/flash-attention.git
  # - cd flash-attention
  # - MAX_JOBS=$((`nproc` - 1)) pip install -v .
  # - cd ..
  # Install TRL
  - git clone https://github.com/huggingface/trl
  - cd trl
  - pip install .
  # Preload the RoCE driver library from the host (for Broadcom driver compatibility)
  - export LD_PRELOAD=/mnt/lib/libbnxt_re-rdmav34.so
  - |
    accelerate launch \
      --multi-gpu \
      --config_file=examples/accelerate_configs/fsdp1.yaml \
      --main_process_ip=$DSTACK_MASTER_NODE_IP \
      --main_process_port=8008 \
      --machine_rank=$DSTACK_NODE_RANK \
      --num_processes=$DSTACK_GPUS_NUM \
      --num_machines=$DSTACK_NODES_NUM \
      trl/scripts/sft.py \
      --model_name_or_path $MODEL_ID \
      --dataset_name trl-lib/Capybara \
      --learning_rate 2.0e-5 \
      --num_train_epochs 1 \
      --packing \
      --per_device_train_batch_size 1 \
      --gradient_accumulation_steps 8 \
      --gradient_checkpointing \
      --eos_token '<|im_end|>' \
      --eval_strategy steps \
      --eval_steps 100 \
      --hub_model_id $HUB_MODEL_ID \
      --output_dir /checkpoints/Qwen3-8B-ft

resources:
  gpu: MI300X:8

