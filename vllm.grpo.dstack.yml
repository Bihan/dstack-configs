type: task
name: open-r1-multi-node

# Size of the cluster
nodes: 2

python: 3.12

nvcc: true

# Required environment variables
env:
  - HF_TOKEN
  - WANDB_API_KEY
  - NCCL_DEBUG=INFO
  # VLLM configuration
  - USE_VLLM=true
  - MODEL=Qwen/Qwen2.5-Coder-7B-Instruct
  - TP=8
  # - DP=1

# Commands of the task
commands:
  - uv pip install vllm==0.8.5.post1 # this will install PyTorch v2.6.0 too.
  - uv pip install setuptools && uv pip install flash-attn --no-build-isolation
  - git clone https://github.com/huggingface/open-r1.git
  - cd open-r1
  - uv pip install .
  - |
    # Get the last IP from DSTACK_NODES_IPS for vLLM node
    VLLM_HOST=$(echo $DSTACK_NODES_IPS | tr ' ' '\n' | tail -n 1)
    echo "VLLM host IP (last node): $VLLM_HOST"
    
    if [ "$USE_VLLM" = "true" ]; then
      # Hardcoded node assignments
      if [ "$DSTACK_NODE_RANK" -eq 1 ]; then
        # Node 1 runs VLLM server
        echo "Starting VLLM server on node 1 (IP: $VLLM_HOST)"
        trl vllm-serve --model $MODEL  --tensor_parallel_size $TP --host 0.0.0.0
      else
        # Node 0 runs training
        echo "Starting training on node 0 with VLLM on $VLLM_HOST"
        accelerate launch --config_file recipes/accelerate_configs/zero3.yaml \
            --num_processes=$DSTACK_GPUS_NUM \
            --num_machines=$DSTACK_NODES_NUM \
            --machine_rank=$DSTACK_NODE_RANK \
            --main_process_ip=$DSTACK_MASTER_NODE_IP \
            --main_process_port=8008 \
            src/open_r1/grpo.py \
            --config recipes/Qwen2.5-Coder-7B-Instruct/grpo/config_codeforces.yaml \
            --hub_model_id sjbbihan/Qwen2.5-Coder-7B-Instruct-Codeforces-GRPO
            --vllm_server_host=$VLLM_HOST
      fi
    else
      # Standard training mode without VLLM
      echo "Running standard training without VLLM"
      accelerate launch --config_file recipes/accelerate_configs/zero3.yaml \
        --num_processes=$DSTACK_GPUS_NUM \
        --num_machines=$DSTACK_NODES_NUM \
        --machine_rank=$DSTACK_NODE_RANK \
        --main_process_ip=$DSTACK_MASTER_NODE_IP \
        --main_process_port=8008 \
        src/open_r1/sft.py \
        --config $CONFIG_FILE
    fi

resources:
  gpu: 80GB:8
  shm_size: 128GB

volumes:
   - /checkpoints:/checkpoints